{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Contents of iPython Notebook\n",
    "\n",
    "Assignment 2 for Advanced Analytics and Machine Learning: Unsupervised Learning of Stock Returns\n",
    "\n",
    "by Maria Athena B Engesaeth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "IPython.OutputArea.auto_scroll_threshold = 9999;"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%javascript\n",
    "IPython.OutputArea.auto_scroll_threshold = 9999;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Python/2.7/site-packages/matplotlib/font_manager.py:273: UserWarning: Matplotlib is building the font cache using fc-list. This may take a moment.\n",
      "  warnings.warn('Matplotlib is building the font cache using fc-list. This may take a moment.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "# Setting up the environment\n",
    "%pylab inline\n",
    "%matplotlib inline\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import sklearn\n",
    "from sklearn import cluster\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "import scipy\n",
    "from scipy.stats import moment\n",
    "from scipy.stats import ttest_ind\n",
    "\n",
    "# For running regressions and R-type formulas\n",
    "import statsmodels\n",
    "import statsmodels.api as sm\n",
    "# R type regression formulas\n",
    "import statsmodels.formula.api as smf\n",
    "\n",
    "import patsy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Filepaths\n",
    "stockreturn2 = '/Users/mariaathena/Dropbox (Personal)/00 Imperial College/1601 Machine Learning/Assignment 2/Data (csv)/stockreturn2.csv'\n",
    "\n",
    "# Load data into dataframe without overriding header and index column of csv\n",
    "stock_df = pd.DataFrame.from_csv(stockreturn2, header=None, index_col=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q1: Descriptive Statistics, Skewness, Kurtosis and % log Returns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>228.0</td>\n",
       "      <td>0.700432</td>\n",
       "      <td>8.639322</td>\n",
       "      <td>-30.36827</td>\n",
       "      <td>-4.604500</td>\n",
       "      <td>1.007143</td>\n",
       "      <td>5.690602</td>\n",
       "      <td>30.29147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>228.0</td>\n",
       "      <td>0.985980</td>\n",
       "      <td>10.593342</td>\n",
       "      <td>-38.55037</td>\n",
       "      <td>-4.796437</td>\n",
       "      <td>1.256301</td>\n",
       "      <td>6.942344</td>\n",
       "      <td>30.29886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>228.0</td>\n",
       "      <td>1.195732</td>\n",
       "      <td>12.103589</td>\n",
       "      <td>-58.86214</td>\n",
       "      <td>-5.041132</td>\n",
       "      <td>1.715627</td>\n",
       "      <td>9.596882</td>\n",
       "      <td>29.13605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>228.0</td>\n",
       "      <td>0.823606</td>\n",
       "      <td>10.297422</td>\n",
       "      <td>-42.58321</td>\n",
       "      <td>-3.527040</td>\n",
       "      <td>0.987606</td>\n",
       "      <td>6.587528</td>\n",
       "      <td>28.19700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>228.0</td>\n",
       "      <td>0.410459</td>\n",
       "      <td>9.582594</td>\n",
       "      <td>-42.28575</td>\n",
       "      <td>-3.476719</td>\n",
       "      <td>0.644807</td>\n",
       "      <td>5.826744</td>\n",
       "      <td>33.02414</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   count      mean        std       min       25%       50%       75%  \\\n",
       "0  228.0  0.700432   8.639322 -30.36827 -4.604500  1.007143  5.690602   \n",
       "1  228.0  0.985980  10.593342 -38.55037 -4.796437  1.256301  6.942344   \n",
       "2  228.0  1.195732  12.103589 -58.86214 -5.041132  1.715627  9.596882   \n",
       "3  228.0  0.823606  10.297422 -42.58321 -3.527040  0.987606  6.587528   \n",
       "4  228.0  0.410459   9.582594 -42.28575 -3.476719  0.644807  5.826744   \n",
       "\n",
       "        max  \n",
       "0  30.29147  \n",
       "1  30.29886  \n",
       "2  29.13605  \n",
       "3  28.19700  \n",
       "4  33.02414  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display table of descriptive statistics of the stock dataframe\n",
    "stock_df.describe().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     -85.040306\n",
       "1    -421.296550\n",
       "2   -1512.910299\n",
       "3    -787.910935\n",
       "4    -895.794816\n",
       "dtype: float64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compute Skewness i.e. 3rd Moment\n",
    "stock_skewness = stock_df.apply(lambda x: moment(x, moment=3))\n",
    "stock_skewness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     23606.425004\n",
       "1     51902.193000\n",
       "2    116253.809928\n",
       "3     60592.462484\n",
       "4     64200.105225\n",
       "dtype: float64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compute Kurtosis i.e. 4th Moment\n",
    "stock_kurtosis = stock_df.apply(lambda x: moment(x, moment=4))\n",
    "stock_kurtosis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>62.0</td>\n",
       "      <td>0.281155</td>\n",
       "      <td>1.484382</td>\n",
       "      <td>-3.640349</td>\n",
       "      <td>-0.533926</td>\n",
       "      <td>0.339213</td>\n",
       "      <td>1.453937</td>\n",
       "      <td>2.753408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>60.0</td>\n",
       "      <td>0.594596</td>\n",
       "      <td>1.759347</td>\n",
       "      <td>-4.302973</td>\n",
       "      <td>-0.327799</td>\n",
       "      <td>0.466436</td>\n",
       "      <td>1.769038</td>\n",
       "      <td>5.631788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>55.0</td>\n",
       "      <td>0.154151</td>\n",
       "      <td>1.804746</td>\n",
       "      <td>-4.882452</td>\n",
       "      <td>-0.717225</td>\n",
       "      <td>0.344449</td>\n",
       "      <td>1.644494</td>\n",
       "      <td>2.912282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>54.0</td>\n",
       "      <td>inf</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-3.859132</td>\n",
       "      <td>-0.779503</td>\n",
       "      <td>0.337790</td>\n",
       "      <td>1.400983</td>\n",
       "      <td>inf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>60.0</td>\n",
       "      <td>0.041246</td>\n",
       "      <td>1.721708</td>\n",
       "      <td>-5.576869</td>\n",
       "      <td>-0.742988</td>\n",
       "      <td>0.106840</td>\n",
       "      <td>1.097747</td>\n",
       "      <td>3.530580</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   count      mean       std       min       25%       50%       75%       max\n",
       "0   62.0  0.281155  1.484382 -3.640349 -0.533926  0.339213  1.453937  2.753408\n",
       "1   60.0  0.594596  1.759347 -4.302973 -0.327799  0.466436  1.769038  5.631788\n",
       "2   55.0  0.154151  1.804746 -4.882452 -0.717225  0.344449  1.644494  2.912282\n",
       "3   54.0       inf       NaN -3.859132 -0.779503  0.337790  1.400983       inf\n",
       "4   60.0  0.041246  1.721708 -5.576869 -0.742988  0.106840  1.097747  3.530580"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compute % log Returns\n",
    "\n",
    "# Firstly we compute the simple returns and store it in a variable\n",
    "simple_ret = stock_df.pct_change()\n",
    "\n",
    "# Then we use this to compute the log returns\n",
    "log_ret = simple_ret.apply(lambda x: np.log(x))\n",
    "\n",
    "# Display table of descriptive statistics of the log returns of the stock dataframe including min and max\n",
    "log_ret.describe().T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q2: Statistical Significance of log Returns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the below regression results we note that all p-values are below 0.05, generally considered the cut-off point for when a variable is statistically insignificant. In other words we fail reject the null hypothesis that mean returns of the stocks are null."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:            stock_df[0]   R-squared:                       0.290\n",
      "Model:                            OLS   Adj. R-squared:                  0.281\n",
      "Method:                 Least Squares   F-statistic:                     30.56\n",
      "Date:                Wed, 30 Mar 2016   Prob (F-statistic):           1.34e-16\n",
      "Time:                        14:56:17   Log-Likelihood:                -775.55\n",
      "No. Observations:                 228   AIC:                             1559.\n",
      "Df Residuals:                     224   BIC:                             1573.\n",
      "Df Model:                           3                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "===============================================================================\n",
      "                  coef    std err          t      P>|t|      [95.0% Conf. Int.]\n",
      "-------------------------------------------------------------------------------\n",
      "Intercept       0.1661      0.488      0.340      0.734        -0.796     1.129\n",
      "stock_df[1]     0.2130      0.057      3.757      0.000         0.101     0.325\n",
      "stock_df[2]     0.1891      0.049      3.864      0.000         0.093     0.286\n",
      "stock_df[3]     0.1191      0.052      2.283      0.023         0.016     0.222\n",
      "==============================================================================\n",
      "Omnibus:                       30.137   Durbin-Watson:                   1.916\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):               70.001\n",
      "Skew:                          -0.608   Prob(JB):                     6.30e-16\n",
      "Kurtosis:                       5.427   Cond. No.                         15.4\n",
      "==============================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "# Design matrices (endog & exog)\n",
    "y, X = patsy.dmatrices('stock_df[0] ~ stock_df[1] + stock_df[2] + stock_df[3]', data=stock_df, return_type='dataframe')\n",
    "\n",
    "#y[:3]\n",
    "#X[:3]\n",
    "\n",
    "mod = sm.OLS(y, X)    # Describe model\n",
    "res = mod.fit()       # Fit model\n",
    "print res.summary()   # Summarize model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q3: Covariance and Correlation Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>74.637889</td>\n",
       "      <td>42.281185</td>\n",
       "      <td>48.026917</td>\n",
       "      <td>30.103004</td>\n",
       "      <td>21.069532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>42.281185</td>\n",
       "      <td>112.218893</td>\n",
       "      <td>70.451876</td>\n",
       "      <td>42.423721</td>\n",
       "      <td>26.299668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>48.026917</td>\n",
       "      <td>70.451876</td>\n",
       "      <td>146.496870</td>\n",
       "      <td>44.594203</td>\n",
       "      <td>29.242793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>30.103004</td>\n",
       "      <td>42.423721</td>\n",
       "      <td>44.594203</td>\n",
       "      <td>106.036892</td>\n",
       "      <td>67.452895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>21.069532</td>\n",
       "      <td>26.299668</td>\n",
       "      <td>29.242793</td>\n",
       "      <td>67.452895</td>\n",
       "      <td>91.826100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           0           1           2           3          4\n",
       "0  74.637889   42.281185   48.026917   30.103004  21.069532\n",
       "1  42.281185  112.218893   70.451876   42.423721  26.299668\n",
       "2  48.026917   70.451876  146.496870   44.594203  29.242793\n",
       "3  30.103004   42.423721   44.594203  106.036892  67.452895\n",
       "4  21.069532   26.299668   29.242793   67.452895  91.826100"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compute Covariance Matrix\n",
    "stock_cov = stock_df.cov()\n",
    "stock_cov"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.461992</td>\n",
       "      <td>0.459294</td>\n",
       "      <td>0.338378</td>\n",
       "      <td>0.254503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.461992</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.549472</td>\n",
       "      <td>0.388908</td>\n",
       "      <td>0.259080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.459294</td>\n",
       "      <td>0.549472</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.357796</td>\n",
       "      <td>0.252128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.338378</td>\n",
       "      <td>0.388908</td>\n",
       "      <td>0.357796</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.683579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.254503</td>\n",
       "      <td>0.259080</td>\n",
       "      <td>0.252128</td>\n",
       "      <td>0.683579</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2         3         4\n",
       "0  1.000000  0.461992  0.459294  0.338378  0.254503\n",
       "1  0.461992  1.000000  0.549472  0.388908  0.259080\n",
       "2  0.459294  0.549472  1.000000  0.357796  0.252128\n",
       "3  0.338378  0.388908  0.357796  1.000000  0.683579\n",
       "4  0.254503  0.259080  0.252128  0.683579  1.000000"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compute Correlation Matrix\n",
    "stock_corr = stock_df.corr()\n",
    "stock_corr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q4: Principal Component Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A Summary of the PCA Approach\n",
    "\n",
    "1. Standardise the data\n",
    "2. Obtain the Eigenvectors and Eigenvalues from the covariance matrix or correlation matrix, or perform Singular Vector Decomposition\n",
    "3. Sort eigenvalues in descending order and choose the k eigenvectors that correspond to the k largest eigenvalues where k is the number of dimensions of the new feature subspace (kâ‰¤d)\n",
    "4. Compute projection matrix (W) from selected k eigenvectors.\n",
    "5. Transform the original dataset X via W to obtain a k-dimensional feature subspace Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Step 1 - Standardise the data\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "stock_std_df = StandardScaler().fit_transform(stock_df)\n",
    "#stock_std_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.42763297 -0.34111318  0.83707913  0.00820318  0.0017559 ]\n",
      " [-0.45989335 -0.35645829 -0.38014075  0.14462186 -0.70428199]\n",
      " [-0.4511153  -0.38546354 -0.38922685  0.02177744  0.70423082]\n",
      " [-0.47856705  0.46946714 -0.04582365 -0.73875733 -0.05207668]\n",
      " [-0.41604893  0.62257349  0.0345571   0.6578606   0.07301211]]\n",
      "eigenvalues:  [ 2.61913608  1.07630477  0.57112107  0.30216155  0.45330297]\n"
     ]
    }
   ],
   "source": [
    "# Step 2 - Obtain the Eigenvectors and Eigenvalues from the covariance matrix or correlation matrix\n",
    "\n",
    "# Covariance matrix of standardised data\n",
    "stock_std_cov = np.cov(stock_std_df.T)\n",
    "\n",
    "# Eigendecomposition on the covariance matrix\n",
    "eig_vals, eig_vecs = np.linalg.eig(stock_std_cov)\n",
    "\n",
    "print eig_vecs\n",
    "print \"eigenvalues: \", eig_vals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.42763297  0.34111318 -0.83707913  0.00820318  0.0017559 ]\n",
      " [ 0.45989335  0.35645829  0.38014075  0.14462186 -0.70428199]\n",
      " [ 0.4511153   0.38546354  0.38922685  0.02177744  0.70423082]\n",
      " [ 0.47856705 -0.46946714  0.04582365 -0.73875733 -0.05207668]\n",
      " [ 0.41604893 -0.62257349 -0.0345571   0.6578606   0.07301211]]\n",
      "eigenvalues:  [ 2.60764864  1.07158414  0.56861615  0.30083628  0.4513148 ]\n"
     ]
    }
   ],
   "source": [
    "# Note: particularly in finance: the correlation matrix is typically used instead of the covariance matrix.\n",
    "# However, the eigendecomposition of the covariance matrix yields the same results as a eigendecomposition \n",
    "# on the correlation matrix, since the correlation matrix can be understood as the normalized covariance matrix.\n",
    "\n",
    "stock_std_corr = np.corrcoef(stock_std_df.T)\n",
    "# Eigendecomposition on the correlation matrix\n",
    "eig_vals, eig_vecs = np.linalg.eig(stock_std_corr)\n",
    "\n",
    "print eig_vecs\n",
    "print \"eigenvalues: \", eig_vals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.60764864283\n",
      "1.07158413686\n",
      "0.568616149904\n",
      "0.451314795061\n",
      "0.300836275345\n"
     ]
    }
   ],
   "source": [
    "# Step 3 - Sorting Eigenvector, Eigenvalue pairs\n",
    "# We look for which eigenvector(s) to drop without losing too much information: The eigenvectors with \n",
    "# the lowest eigenvalues bear the least information about the distribution of the data.\n",
    "\n",
    "# Make a list of (eigenvalue, eigenvector) tuples\n",
    "eig_pairs = [(np.abs(eig_vals[i]), eig_vecs[:,i]) for i in range(len(eig_vals))]\n",
    "\n",
    "# Sort the (eigenvalue, eigenvector) tuples from high to low\n",
    "eig_pairs.sort()\n",
    "eig_pairs.reverse()\n",
    "\n",
    "for i in eig_pairs:\n",
    "    print(i[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 52.15297286  21.43168274  11.372323     9.0262959    6.01672551]\n"
     ]
    }
   ],
   "source": [
    "# Compute explained variance to find how much information (variance) can be attributed to each of \n",
    "# the principal components in our new feature subspace.\n",
    "tot = sum(eig_vals)\n",
    "var_exp = [(i / tot)*100 for i in sorted(eig_vals, reverse=True)]\n",
    "var_exp = np.array(var_exp)\n",
    "cum_var_exp = np.cumsum(var_exp)\n",
    "print var_exp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.42763297  0.34111318]\n",
      " [ 0.45989335  0.35645829]\n",
      " [ 0.4511153   0.38546354]\n",
      " [ 0.47856705 -0.46946714]\n",
      " [ 0.41604893 -0.62257349]]\n"
     ]
    }
   ],
   "source": [
    "# Step 4 - Projection Matrix\n",
    "# The projection matrix is used to transform the dataset to the new feature subspace\n",
    "matrix_w = np.hstack((eig_pairs[0][1].reshape(5,1),\n",
    "                      eig_pairs[1][1].reshape(5,1)))\n",
    "\n",
    "print matrix_w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.12002894,  0.36714174],\n",
       "       [ 1.20452326,  0.38365776],\n",
       "       [ 1.18153237,  0.41487625],\n",
       "       [ 1.25343223, -0.50528972],\n",
       "       [ 1.08968876, -0.67007882]])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 5 - Project the dataset onto the new feature subspace\n",
    "Y = stock_std_cov.dot(matrix_w)\n",
    "Y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q5: Interpretation and Analysis\n",
    "##### incl. Bonus Question\n",
    "\n",
    "To answer the question of how many components explain the data it can be helpful to look at a visualisation of the cumulative variance of each added principal component. As seen in the below plot, the first three (3) prinicpal components explain over 80% of the variation in the data and it may be reasonable to conclude that these three principal components would suffice in explaining the data.\n",
    "\n",
    "To answer the same questions qualitatively, that is, given the nature of our data we might want to remind ourselves that this is financial data. Each component relates to a stock, companies within the same industry (or perfectly complimentary industries) tend to experience the similar variance. It seems reaonable to assume that a minimum of two (2), and possibly more, of these stocks are from companies in the same industry."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAakAAAEbCAYAAABgLnslAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10dc19690>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "with plt.style.context('seaborn-whitegrid'):\n",
    "    plt.figure(figsize=(6, 4))\n",
    "\n",
    "    plt.bar(range(5), var_exp, alpha=0.5, align='center',\n",
    "            label='individual explained variance')\n",
    "    plt.step(range(5), cum_var_exp, where='mid',\n",
    "             label='cumulative explained variance')\n",
    "    plt.ylabel('Explained variance ratio')\n",
    "    plt.xlabel('Principal components')\n",
    "    plt.legend(loc='best')\n",
    "    plt.tight_layout()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
