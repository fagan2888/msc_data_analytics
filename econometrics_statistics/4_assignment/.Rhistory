load("/Users/MariaAthena/Dropbox/00 Imperial College/Statistics and Econometrics/Lecture 2/wage1.RData")
packages
install packages
install packages from CRAN
library()
search(car)
setwd(/Users/MariaAthena/Downloads)
setwd('/Users/MariaAthena/Downloads')
R CMD INSTALL [car] pkgs
R CMD INSTALL pkgs
?install
R CMD INSTALL
updateR()
install.packages("installr")
library(installr)
updateR()
?car
car
package car
car
search(car)
library()
library(swirl)
swirl()
wd
setwd('/Users/MariaAthena/Repositories/GitHub')
library(swirl)
install_course_zip("path/to/file/here/swirl_courses-master.zip", multi=TRUE,
which_course="Data_Analysis")
install_course_zip(multi=TRUE,
which_course="Data_Analysis")
install_course_zip(path, multi=TRUE,
which_course="Data_Analysis")
install_course_zip('/Users/MariaAthena/Repositories/GitHub/swirl_courses', multi=TRUE, which_course="Data_Analysis")
?install_course_zip
?install_course_zip
install_course('/Users/MariaAthena/Repositories/GitHub/swirl_courses', multi=TRUE, which_course="Data_Analysis")
install_course
?install_course
library(swirl)
install_from_swirl("Data_Analysis")
swirl()
swirl()
'cars'
cars
mpgCity <- cars$mpgCity
mpgCity <- 'cars$mpgCity'
quit()
load("/Users/MariaAthena/Dropbox/00 Imperial College/Statistics and Econometrics/Lecture 8/hprice1.RData")
desc
model.1 <- lm(price ~ lotsize + sqrft + bdrms, data)
model.2 <- lm(log(price) ~ log(sqrft) + log(bdrms), data)
resettest(model.1, type = "fitted")
resettest(model.2, type = "fitted")
jtest(model.1, model.2)
library(lmtest)
resettest(model.1, type = "fitted")
resettest(model.2, type = "fitted")
jtest(model.1, model.2)
model.2 <- lm(log(price) ~ log(sqrft) + log(bdrms), data)
summary(model.2)
model.1 <- lm(log(price) ~ lotsize + sqrft + bdrms, data)
model.2 <- lm(log(price) ~ log(lotsize) + log(sqrft) + log(bdrms), data)
jtest(model.1, model.2)
model.2 <- lm(log(price) ~ log(lotsize) + log(sqrft) + bdrms, data)
jtest(model.1, model.2)
model.1 <- lm(price ~ lotsize + sqrft + bdrms, data)
model.2 <- lm(log(price) ~ log(sqrft) + log(bdrms), data)
model.1 <- lm(log(price) ~ lotsize + sqrft + bdrms, data)
model.2 <- lm(log(price) ~ log(lotsize) + log(sqrft) + bdrms, data)
jtest(model.1, model.2)
load("/Users/MariaAthena/Dropbox/00 Imperial College/Statistics and Econometrics/Lecture 8/crime2.RData")
desc
install.packages("AER")
library(AER)
install.packages("plm")
library("plm")
load("/Users/MariaAthena/Dropbox/00 Imperial College/Statistics and Econometrics/Lecture 9/crime2.RData")
desc
### Maria Athena B. Engesaeth
### CID 01159179
##################################################################################
setwd("/Users/MariaAthena/Dropbox/00 Imperial College/Statistics and Econometrics/Problem Set 4")
##################################################################################
load("meap00_01.RData")
desc
## 1. Data from Michigan Department of Education on students level of
## proficiency in reading and math
# A. Estimate OLS model and obtain standard errors and robust standard errors.
#
# Estimating: math4 = β0 + β1lunch + β2 log(enroll) + β3 log(exppp) + u
math.model <- lm(formula = math4 ~ lunch + lenroll + lexppp, data)
summary(math.model)
#
# SRF: math4 = 91.93 - 0.45 lunch - 5.40 log(enroll) + 3.52 log(exppp)
# Sample size: 1,692
# R-squared: 0.3729 - i.e. in this sample data, 37.29% of the proportion of the
# students' achieving satisfactory marks in 4th grade math is explained by the
# variables in this model.
# P-value: 2.2e-16 <<< very small
# We find that unlike expenditure per pupil, neither eligibility for subsidized
# lunch nor school enrollment is statistically significant, and their effects
# are not practically large.
# se(lunch): 0.01
# se(log(enroll)): 0.94
# se(log(exppp)): 2.10
#
library(sandwich)
library(lmtest)
vcov.robust <- vcovHC(math.model, "HC1")
coeftest(math.model, vcov=vcov.robust)
# robust se(lunch): 0.01
# robust se(log(enroll)): 1.13
# robust se(log(exppp)): 2.35
# As expected the robust standard errors are larger than the OLS standard errors
# as they usually are when the error terms are heteroskedastic.
# B. White test for heteroskedasticity. F test, and conclusion.
#
# We do an F test comparing the regular OLS and the robust OLS model, this allows
# us to conclude if the the error terms
# H0: delta_1 = delta_2 = delta_3 = 0
# H1 != H0
fitted.math <- math.model$fitted.values
bptest(math.model, ~fitted.math+I(fitted.math^2))
# OR
library(car)
linearHypothesis(math.model, c("lunch=0", "lenroll=0", "lexppp=0"),
vcov.=vcov.robust, white.adjust="hc1")
qf(0.95, 1691, 1698)
# F-stat: 247.9 >> [1.1]
# P-value: 2.2e-16 <<< small
# Conclusion -> We fail to reject the null hypothesis that the error terms are
# non heteroskedastic, the squared error terms may have a linear relationship
# to the independant variables.
# C. Weighted Least Square (WLS) Method to predict math proficiency of students.
#
# First we calculate the log of the square of the residuals
aux.y <- log(math.model$residuals^2)
# then we find the fitted values (g(x)) value to weight the model against
aux.model <- lm(aux.y ~ fitted.model$fitted.values +
I(fitted.model$fitted.values^2), data)
#
# We then find the h=exp(g) to weight the OLS model using WLS with weight 1/h
# i.e. each variable is divided by 1/h
h <- exp(aux.model$fitted.values)
math.wls <- lm(math4 ~ lunch + lenroll + lexppp, data = data, weights = 1/h)
summary(math.wls)
aux.model <- lm(aux.y ~ fitted.model$fitted.values +
I(fitted.model$fitted.values^2), data)
### Maria Athena B. Engesaeth
### CID 01159179
##################################################################################
setwd("/Users/MariaAthena/Dropbox/00 Imperial College/Statistics and Econometrics/Problem Set 4")
##################################################################################
load("meap00_01.RData")
desc
## 1. Data from Michigan Department of Education on students level of
## proficiency in reading and math
# A. Estimate OLS model and obtain standard errors and robust standard errors.
#
# Estimating: math4 = β0 + β1lunch + β2 log(enroll) + β3 log(exppp) + u
math.model <- lm(formula = math4 ~ lunch + lenroll + lexppp, data)
summary(math.model)
#
# SRF: math4 = 91.93 - 0.45 lunch - 5.40 log(enroll) + 3.52 log(exppp)
# Sample size: 1,692
# R-squared: 0.3729 - i.e. in this sample data, 37.29% of the proportion of the
# students' achieving satisfactory marks in 4th grade math is explained by the
# variables in this model.
# P-value: 2.2e-16 <<< very small
# We find that unlike expenditure per pupil, neither eligibility for subsidized
# lunch nor school enrollment is statistically significant, and their effects
# are not practically large.
# se(lunch): 0.01
# se(log(enroll)): 0.94
# se(log(exppp)): 2.10
#
library(sandwich)
library(lmtest)
vcov.robust <- vcovHC(math.model, "HC1")
coeftest(math.model, vcov=vcov.robust)
# robust se(lunch): 0.01
# robust se(log(enroll)): 1.13
# robust se(log(exppp)): 2.35
# As expected the robust standard errors are larger than the OLS standard errors
# as they usually are when the error terms are heteroskedastic.
# B. White test for heteroskedasticity. F test, and conclusion.
#
# We do an F test comparing the regular OLS and the robust OLS model, this allows
# us to conclude if the the error terms
# H0: delta_1 = delta_2 = delta_3 = 0
# H1 != H0
fitted.math <- math.model$fitted.values
bptest(math.model, ~fitted.math+I(fitted.math^2))
# OR
library(car)
linearHypothesis(math.model, c("lunch=0", "lenroll=0", "lexppp=0"),
vcov.=vcov.robust, white.adjust="hc1")
qf(0.95, 1691, 1698)
# F-stat: 247.9 >> [1.1]
# P-value: 2.2e-16 <<< small
# Conclusion -> We fail to reject the null hypothesis that the error terms are
# non heteroskedastic, the squared error terms may have a linear relationship
# to the independant variables.
# C. Weighted Least Square (WLS) Method to predict math proficiency of students.
#
# First we calculate the log of the square of the residuals
aux.y <- log(math.model$residuals^2)
# then we find the fitted values (g(x)) value to weight the model against
aux.model <- lm(aux.y ~ fitted.model$fitted.values +
I(fitted.model$fitted.values^2), data)
#
# We then find the h=exp(g) to weight the OLS model using WLS with weight 1/h
# i.e. each variable is divided by 1/h
h <- exp(aux.model$fitted.values)
math.wls <- lm(math4 ~ lunch + lenroll + lexppp, data = data, weights = 1/h)
summary(math.wls)
setwd("/Users/MariaAthena/Dropbox/00 Imperial College/Statistics and Econometrics/Problem Set 4")
##################################################################################
load("meap00_01.RData")
desc
math.model <- lm(formula = math4 ~ lunch + lenroll + lexppp, data)
summary(math.model)
library(sandwich)
library(lmtest)
vcov.robust <- vcovHC(math.model, "HC1")
coeftest(math.model, vcov=vcov.robust)
# OR
library(car)
linearHypothesis(math.model, c("lunch=0", "lenroll=0", "lexppp=0"),
vcov.=vcov.robust, white.adjust="hc1")
qf(0.95, 1691, 1698)
aux.y <- log(math.model$residuals^2)
# then we find the fitted values (g(x)) value to weight the model against
aux.model <- lm(aux.y ~ fitted.model$fitted.values +
I(fitted.model$fitted.values^2), data)
#
aux.model <- lm(aux.y ~ fitted.math$fitted.values +
I(fitted.math$fitted.values^2), data)
aux.model <- lm(aux.y ~ fitted.model$fitted.values +
I(fitted.model$fitted.values^2), data)
aux.y <- log(math.model$residuals^2)
h <- exp(aux.model$fitted.values)
math.wls <- lm(math4 ~ lunch + lenroll + lexppp, data = data, weights = 1/h)
summary(math.wls)
#
